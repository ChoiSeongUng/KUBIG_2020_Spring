{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Model 1 - with Boston Housing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Tutorial]** 본격적으로 들어가기 전에 먼저 독립 변수가 한 개인 가장 기본적인 Linear Regression을 적합시켜 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Sample regression problem with one input variable')\n",
    "X, y = make_regression(n_samples = 100, n_features=1,n_informative=1, \n",
    "                             bias = 150.0, noise = 30, random_state=1)\n",
    "plt.scatter(X, y, marker= 'o', s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 random data를 생성했습니다. 이제 Linear Regression을 적용해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "print('linear model coef (w): {}'.format(reg.coef_))\n",
    "print('linear model intercept (b): {:.3f}'.format(reg.intercept_))\n",
    "print('R-squared score (training): {:.3f}'.format(reg.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}'.format(reg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "적합시킨 모델을 그림 위에 나타내어 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X, y, marker= 'o', s=50, alpha=0.8)\n",
    "plt.plot(X, reg.coef_ * X + reg.intercept_, 'r-')\n",
    "plt.title('Least-squares linear regression')\n",
    "plt.xlabel('Feature value (x)')\n",
    "plt.ylabel('Target value (y)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 본격적으로 **보스턴 하우징 데이터**를 이용하여 2주차 세션에서 배웠던 Linear, Ridge, Lasso regression, Elastic Net을 적용해봅시다. \n",
    "\n",
    "다음의 모듈을 import 하세요.\n",
    "\n",
    "- sklearn.datasets : load_boston\n",
    "- sklearn.linear_model : LinearRegression, Ridge, Lasso, ElasticNet\n",
    "- sklearn.model_selection : cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load_boston 함수를 이용하여 boston이라는 이름으로 데이터를 로드하세요.\n",
    "boston 데이터를 파악하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = ______\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(boston.data,columns=boston.feature_names)\n",
    "df['target']=boston.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('target',axis=1)\n",
    "y=df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Linear Regression**\n",
    "\n",
    "- train set과 test set을 분리하세요. 이 때, test set의 크기는 0.3, random state는 20으로 하세요.\n",
    "- reg_linear라는 이름으로 Linear Regression을 생성하세요.\n",
    "- train set에 모델을 적합시키세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ______(__, __, ______=___, ______ = ___)\n",
    "reg_linear =_______\n",
    "______.___(______, ______)\n",
    "\n",
    "cv_linear=cross_val_score(estimator=reg_linear, X=X_train, y=y_train, cv=10)\n",
    "\n",
    "print(\"CV score: \",cv_linear.mean())\n",
    "print('R-squared score (training): {:.3f}'.format(reg_linear.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}'.format(reg_linear.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge Regression**\n",
    "\n",
    "- alpha의 값을 0.005, normalize=True로 하여, reg_ridge라는 이름으로 Ridge Regression을 생성하세요.\n",
    "- train set에 대하여 모델을 적합시키세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_ridge=_____(____=____, ______=____)\n",
    "______.___(______, ______)\n",
    "\n",
    "cv_ridge=cross_val_score(reg_ridge, X_train, y_train, cv=10)\n",
    "\n",
    "print(\"CV score: \",np.mean(cv_ridge))\n",
    "print(\"R^2 for training data: {}\".format(reg_ridge.score(X_train, y_train)))\n",
    "print(\"R^2 for test data: {}\".format(reg_ridge.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "알파의 값을 임의로 지정해서 적합시켜 보았습니다.\n",
    "​\n",
    " 그럼 이제 알파의 값에 따라 CV 스코어가 어떻게 변하는지 그림으로 나타내어 봅시다. 아래의 코드를 실행시켜 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_plot(cv_scores, cv_scores_std):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(alpha_space, cv_scores)\n",
    "\n",
    "    std_error = cv_scores_std / np.sqrt(10)\n",
    "\n",
    "    ax.fill_between(alpha_space, cv_scores + std_error, cv_scores - std_error, alpha=0.2)\n",
    "    ax.set_ylabel('CV Score +/- Std Error')\n",
    "    ax.set_xlabel('Alpha')\n",
    "    ax.axhline(np.max(cv_scores), linestyle='--', color='.5')\n",
    "    ax.set_xlim([alpha_space[0], alpha_space[-1]])\n",
    "    ax.set_xscale('log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(normalize=True)\n",
    "\n",
    "alpha_space = np.logspace(-6, 0, 50)\n",
    "ridge_scores = []\n",
    "ridge_scores_std = []\n",
    "\n",
    "for alpha in alpha_space:\n",
    "    ridge.alpha = alpha\n",
    "    ridge_cv_scores = cross_val_score(ridge, X_train, y_train, cv=10)\n",
    "    ridge_scores.append(np.mean(ridge_cv_scores))\n",
    "    ridge_scores_std.append(np.std(ridge_cv_scores))\n",
    "    \n",
    "display_plot(ridge_scores, ridge_scores_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "번외로 Ridge Regression에 Polynomial Feature를 추가한 모델을 적합시켜 보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "steps = [\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', Ridge(alpha=2, fit_intercept=True))\n",
    "]\n",
    "\n",
    "ridge_pipe = Pipeline(steps)\n",
    "ridge_pipe.fit(X_train, y_train)\n",
    "\n",
    "cv_ridge = cross_val_score(estimator = ridge_pipe, X = X_train, y = y_train.ravel(), cv = 10)\n",
    "\n",
    "print('CV: ', cv_ridge.mean())\n",
    "print(\"R^2 for training data: {}\".format(ridge_pipe.score(X_train, y_train)))\n",
    "print(\"R^2 for test data: {}\".format(ridge_pipe.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso Regresson**\n",
    "- alpha의 값을 0.005, normalize=True로 하여, reg_lasso라는 이름으로 Lasso Regression을 생성하세요.\n",
    "- train set에 대하여 모델을 적합시키세요.\n",
    "- 적합시킨 모델과 train set에 대하여 cross_val_score를 호출하세요. 이때 cv=10으로 하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lasso = _____(____=_____, ______=____)\n",
    "______.___(______, ______)\n",
    "\n",
    "cv_lasso=_________(________,______, ______, ___=__)\n",
    "\n",
    "print(\"CV score: \",cv_lasso.mean())\n",
    "print(\"R^2 for training data: {}\".format(reg_lasso.score(X_train, y_train)))\n",
    "print(\"R^2 for test data: {}\".format(reg_lasso.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso**의 경우도 알파의 값에 따라 CV 스코어가 어떻게 변화하는지 그림으로 나타내어 봅시다.\n",
    "위 Ridge Regression의 경우를 참고하세요.\n",
    "\n",
    "- lasso라는 이름으로 Lasso Regression을 생성하세요. 이때, normalize=True로 하세요.\n",
    "- train set에 대하여 cross_val_score 함수를 호출하세요. 이 때, cv=10으로 하세요.\n",
    "- display_plot을 호출하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = _____(______=____)\n",
    "\n",
    "alpha_space = np.logspace(-6, 0, 50)\n",
    "lasso_scores = []\n",
    "lasso_scores_std = []\n",
    "\n",
    "for alpha in alpha_space:\n",
    "    lasso.alpha = alpha\n",
    "    lasso_cv_scores = ________(_____, ______, ______, ___=__)\n",
    "    lasso_scores.append(np.mean(lasso_cv_scores))\n",
    "    lasso_scores_std.append(np.std(lasso_cv_scores))\n",
    "    \n",
    "______(________, ________)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마찬가지로, Lasso Regression에 Polynomial Feature를 추가하여 적합시켜 봅시다.\n",
    "\n",
    "- 스케일러는 StandardScaler을 이용하세요.\n",
    "- 모델은 알파=0.02로 하는 Lasso Regression을 이용하세요.\n",
    "- Pipeline을 적용하세요.\n",
    "- train data에 대하여 Pipeline을 적합시키세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    ('scalar', _________),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model',_____(____=____, fit_intercept=True))\n",
    "]\n",
    "\n",
    "lasso_pipe = ______(_____)\n",
    "________.___(______, ______)\n",
    "\n",
    "cv_lasso = cross_val_score(estimator = lasso_pipe, X = X_train, y = y_train, cv = 10)\n",
    "\n",
    "print(\"CV score: \", cv_lasso.mean())\n",
    "print(\"R^2 for training data: {}\".format(lasso_pipe.score(X_train, y_train)))\n",
    "print(\"R^2 for test data: {}\".format(lasso_pipe.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elastic Net**\n",
    "\n",
    "마지막으로 Elastic Net을 간단하게 적용해보고 마무리합시다. Elastic Net을 적용시키기 위해서는 최적의 모수 조합을 찾아야 합니다. \n",
    "\n",
    "GirdSearchCV를 이용하여 최적의 모수 조합을 찾도록 합시다. 다음의 모듈을 import 하세요.\n",
    "\n",
    "- sklearn.model_selection : GridSearchCV\n",
    "- sklearn.metrics : mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reg_enet이라는 이름으로 ElasticNet을 생성하세요. 이때, normalize=True로 하세요.\n",
    "- train set에 대하여 search를 적합시키세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_enet=_______(______=____)\n",
    "search=GridSearchCV(estimator=reg_enet,param_grid={'alpha':np.logspace(-5,2,8),'l1_ratio':[.2,.4,.6,.8]},\n",
    "                    scoring='neg_mean_squared_error',n_jobs=1,refit=True,cv=10)\n",
    "______.____(______,______)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 결과에서 나온 알파와 ㅣ1_ratio의 값을 대입하여 ElasticNet을 생성하세요.\n",
    "- train data에 대하여 모델을 적합시키세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_enet=_______(normalize=True, alpha=______, l1_ratio=_____)\n",
    "_______.___(______, ______)\n",
    "\n",
    "cv_lasso=cross_val_score(reg_enet, X_train, y_train, cv=10)\n",
    "\n",
    "print(\"CV score: \",cv_lasso.mean())\n",
    "print(\"R^2 for training data: {}\".format(reg_enet.score(X_train, y_train)))\n",
    "print(\"R^2 for test data: {}\".format(reg_enet.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수고하셨습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
